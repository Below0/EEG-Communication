{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import random\n",
    "\n",
    "\n",
    "#test1=pd.read_csv('Result_per_second.csv')\n",
    "#test2=pd.read_csv('Result_game.csv')\n",
    "test1=pd.read_csv('normal4.csv', header=None)\n",
    "test2=pd.read_csv('emer4.csv', header=None)\n",
    "\n",
    "#test1 = test1.drop([\"Time\", \"Unnamed: 0\"], axis=1)\n",
    "#test2 = test2.drop([\"Time\", \"Unnamed: 0\"], axis=1)\n",
    "\n",
    "\n",
    "#test1.head()\n",
    "#print(test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1[\"label\"] = \"unsafe\"\n",
    "test2[\"label\"] = \"safe\"\n",
    "\n",
    "csv=pd.concat([test1, test2])\n",
    "\n",
    "bclass = {'safe':[1, 0], 'unsafe':[0, 1]}\n",
    "y = np.empty((1123, 2))\n",
    "for i, v in enumerate(csv['label']):\n",
    "    y[i] = bclass[v]\n",
    "\n",
    "del csv['label']\n",
    "#X = csv[['delta','theta','lowAlpha','highAlpha','lowBeta','highBeta','lowGamma','midGamma','Meditation','Attention']].to_numpy()\n",
    "X=csv.to_numpy()\n",
    "\n",
    "#scaler = RobustScaler()\n",
    "#scaler.fit(X)\n",
    "#X = scaler.transform(X)\n",
    "#print(X_rob)\n",
    "#np.mean(X_rob), np.std(X_rob)\n",
    "\n",
    "tmp = [[x,y_tmp] for x, y_tmp in zip(X, y)]\n",
    "random.shuffle(tmp)\n",
    "X= [n[0] for n in tmp]\n",
    "y = [n[1] for n in tmp]\n",
    "\n",
    "X = np.asarray(X, dtype=np.float32)\n",
    "y = np.asarray(y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(899, 10) (899, 2) (223, 10) (223, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = X[1:900], y[1:900]\n",
    "x_test, y_test = X[900:], y[900:]\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\"\"\"\n",
    "model.add(Convolution2D(32, 3, 3,\n",
    "                        border_mode='same',\n",
    "                        input_shape=X_train.shape[1:]))\n",
    "                        \"\"\"\n",
    "model.add(Dense(512, input_shape=(10,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 899 samples, validate on 223 samples\n",
      "Epoch 1/50\n",
      "899/899 [==============================] - 0s 311us/step - loss: 0.5029 - accuracy: 0.7709 - val_loss: 0.4840 - val_accuracy: 0.8072\n",
      "Epoch 2/50\n",
      "899/899 [==============================] - 0s 135us/step - loss: 0.4028 - accuracy: 0.8242 - val_loss: 0.4660 - val_accuracy: 0.8027\n",
      "Epoch 3/50\n",
      "899/899 [==============================] - 0s 148us/step - loss: 0.3761 - accuracy: 0.8432 - val_loss: 0.4311 - val_accuracy: 0.8296\n",
      "Epoch 4/50\n",
      "899/899 [==============================] - 0s 148us/step - loss: 0.3534 - accuracy: 0.8610 - val_loss: 0.4708 - val_accuracy: 0.8117\n",
      "Epoch 5/50\n",
      "899/899 [==============================] - 0s 146us/step - loss: 0.3500 - accuracy: 0.8498 - val_loss: 0.5403 - val_accuracy: 0.7444\n",
      "Epoch 6/50\n",
      "899/899 [==============================] - 0s 151us/step - loss: 0.3420 - accuracy: 0.8587 - val_loss: 0.4751 - val_accuracy: 0.8117\n",
      "Epoch 7/50\n",
      "899/899 [==============================] - 0s 145us/step - loss: 0.3169 - accuracy: 0.8743 - val_loss: 0.3728 - val_accuracy: 0.8341\n",
      "Epoch 8/50\n",
      "899/899 [==============================] - 0s 160us/step - loss: 0.3136 - accuracy: 0.8654 - val_loss: 0.4083 - val_accuracy: 0.8206\n",
      "Epoch 9/50\n",
      "899/899 [==============================] - 0s 142us/step - loss: 0.2964 - accuracy: 0.8776 - val_loss: 0.3516 - val_accuracy: 0.8430\n",
      "Epoch 10/50\n",
      "899/899 [==============================] - 0s 139us/step - loss: 0.2913 - accuracy: 0.8910 - val_loss: 0.3467 - val_accuracy: 0.8610\n",
      "Epoch 11/50\n",
      "899/899 [==============================] - 0s 203us/step - loss: 0.2891 - accuracy: 0.8854 - val_loss: 0.4146 - val_accuracy: 0.8341\n",
      "Epoch 12/50\n",
      "899/899 [==============================] - 0s 192us/step - loss: 0.2855 - accuracy: 0.8966 - val_loss: 0.3765 - val_accuracy: 0.8475\n",
      "Epoch 13/50\n",
      "899/899 [==============================] - 0s 200us/step - loss: 0.2801 - accuracy: 0.8932 - val_loss: 0.4547 - val_accuracy: 0.8251\n",
      "Epoch 14/50\n",
      "899/899 [==============================] - 0s 180us/step - loss: 0.2830 - accuracy: 0.8843 - val_loss: 0.3550 - val_accuracy: 0.8430\n",
      "Epoch 15/50\n",
      "899/899 [==============================] - 0s 192us/step - loss: 0.2623 - accuracy: 0.9043 - val_loss: 0.4211 - val_accuracy: 0.8430\n",
      "Epoch 16/50\n",
      "899/899 [==============================] - 0s 199us/step - loss: 0.2713 - accuracy: 0.8966 - val_loss: 0.4553 - val_accuracy: 0.8341\n",
      "Epoch 17/50\n",
      "899/899 [==============================] - 0s 172us/step - loss: 0.2636 - accuracy: 0.8877 - val_loss: 0.3244 - val_accuracy: 0.8700\n",
      "Epoch 18/50\n",
      "899/899 [==============================] - 0s 166us/step - loss: 0.2454 - accuracy: 0.9088 - val_loss: 0.5468 - val_accuracy: 0.7354\n",
      "Epoch 19/50\n",
      "899/899 [==============================] - 0s 144us/step - loss: 0.2662 - accuracy: 0.8899 - val_loss: 0.3244 - val_accuracy: 0.8744\n",
      "Epoch 20/50\n",
      "899/899 [==============================] - 0s 143us/step - loss: 0.2499 - accuracy: 0.9055 - val_loss: 0.3941 - val_accuracy: 0.8251\n",
      "Epoch 21/50\n",
      "899/899 [==============================] - 0s 138us/step - loss: 0.2480 - accuracy: 0.8966 - val_loss: 0.3864 - val_accuracy: 0.8430\n",
      "Epoch 22/50\n",
      "899/899 [==============================] - 0s 138us/step - loss: 0.2521 - accuracy: 0.8843 - val_loss: 0.4237 - val_accuracy: 0.8430\n",
      "Epoch 23/50\n",
      "899/899 [==============================] - 0s 138us/step - loss: 0.2421 - accuracy: 0.9010 - val_loss: 0.3468 - val_accuracy: 0.8789\n",
      "Epoch 24/50\n",
      "899/899 [==============================] - 0s 142us/step - loss: 0.2329 - accuracy: 0.9110 - val_loss: 0.4212 - val_accuracy: 0.8430\n",
      "Epoch 25/50\n",
      "899/899 [==============================] - 0s 223us/step - loss: 0.2433 - accuracy: 0.9021 - val_loss: 0.3600 - val_accuracy: 0.8700\n",
      "Epoch 26/50\n",
      "899/899 [==============================] - 0s 220us/step - loss: 0.2315 - accuracy: 0.9121 - val_loss: 0.3485 - val_accuracy: 0.8610\n",
      "Epoch 27/50\n",
      "899/899 [==============================] - 0s 202us/step - loss: 0.2200 - accuracy: 0.9032 - val_loss: 0.4296 - val_accuracy: 0.8161\n",
      "Epoch 28/50\n",
      "899/899 [==============================] - 0s 195us/step - loss: 0.2299 - accuracy: 0.9021 - val_loss: 0.3438 - val_accuracy: 0.8744\n",
      "Epoch 29/50\n",
      "899/899 [==============================] - 0s 204us/step - loss: 0.2093 - accuracy: 0.9110 - val_loss: 0.3445 - val_accuracy: 0.8700\n",
      "Epoch 30/50\n",
      "899/899 [==============================] - 0s 154us/step - loss: 0.2192 - accuracy: 0.9121 - val_loss: 0.3483 - val_accuracy: 0.8834\n",
      "Epoch 31/50\n",
      "899/899 [==============================] - 0s 151us/step - loss: 0.2185 - accuracy: 0.9132 - val_loss: 0.3671 - val_accuracy: 0.8834\n",
      "Epoch 32/50\n",
      "899/899 [==============================] - 0s 166us/step - loss: 0.2014 - accuracy: 0.9132 - val_loss: 0.3860 - val_accuracy: 0.8700\n",
      "Epoch 33/50\n",
      "899/899 [==============================] - 0s 219us/step - loss: 0.1984 - accuracy: 0.9166 - val_loss: 0.4487 - val_accuracy: 0.8475\n",
      "Epoch 34/50\n",
      "899/899 [==============================] - 0s 214us/step - loss: 0.2106 - accuracy: 0.9166 - val_loss: 0.3893 - val_accuracy: 0.8565\n",
      "Epoch 35/50\n",
      "899/899 [==============================] - 0s 179us/step - loss: 0.2036 - accuracy: 0.9177 - val_loss: 0.5512 - val_accuracy: 0.8386\n",
      "Epoch 36/50\n",
      "899/899 [==============================] - 0s 184us/step - loss: 0.2042 - accuracy: 0.9121 - val_loss: 0.4143 - val_accuracy: 0.8296\n",
      "Epoch 37/50\n",
      "899/899 [==============================] - 0s 184us/step - loss: 0.1890 - accuracy: 0.9210 - val_loss: 0.4304 - val_accuracy: 0.8610\n",
      "Epoch 38/50\n",
      "899/899 [==============================] - 0s 144us/step - loss: 0.1979 - accuracy: 0.9166 - val_loss: 0.3936 - val_accuracy: 0.8386\n",
      "Epoch 39/50\n",
      "899/899 [==============================] - 0s 162us/step - loss: 0.1973 - accuracy: 0.9221 - val_loss: 0.3968 - val_accuracy: 0.8565\n",
      "Epoch 40/50\n",
      "899/899 [==============================] - 0s 134us/step - loss: 0.1999 - accuracy: 0.9099 - val_loss: 0.4538 - val_accuracy: 0.8700\n",
      "Epoch 41/50\n",
      "899/899 [==============================] - 0s 132us/step - loss: 0.2012 - accuracy: 0.9188 - val_loss: 0.3862 - val_accuracy: 0.8655\n",
      "Epoch 42/50\n",
      "899/899 [==============================] - 0s 149us/step - loss: 0.1982 - accuracy: 0.9232 - val_loss: 0.4613 - val_accuracy: 0.8565\n",
      "Epoch 43/50\n",
      "899/899 [==============================] - 0s 151us/step - loss: 0.1877 - accuracy: 0.9221 - val_loss: 0.4654 - val_accuracy: 0.8655\n",
      "Epoch 44/50\n",
      "899/899 [==============================] - 0s 145us/step - loss: 0.1911 - accuracy: 0.9266 - val_loss: 0.5127 - val_accuracy: 0.8565\n",
      "Epoch 45/50\n",
      "899/899 [==============================] - 0s 148us/step - loss: 0.1741 - accuracy: 0.9255 - val_loss: 0.4178 - val_accuracy: 0.8700\n",
      "Epoch 46/50\n",
      "899/899 [==============================] - 0s 234us/step - loss: 0.1796 - accuracy: 0.9288 - val_loss: 0.4873 - val_accuracy: 0.8655\n",
      "Epoch 47/50\n",
      "899/899 [==============================] - 0s 197us/step - loss: 0.1691 - accuracy: 0.9333 - val_loss: 0.4049 - val_accuracy: 0.8700\n",
      "Epoch 48/50\n",
      "899/899 [==============================] - 0s 191us/step - loss: 0.1762 - accuracy: 0.9244 - val_loss: 0.4312 - val_accuracy: 0.8430\n",
      "Epoch 49/50\n",
      "899/899 [==============================] - 0s 212us/step - loss: 0.1717 - accuracy: 0.9299 - val_loss: 0.5114 - val_accuracy: 0.7982\n",
      "Epoch 50/50\n",
      "899/899 [==============================] - 0s 203us/step - loss: 0.1802 - accuracy: 0.9266 - val_loss: 0.4185 - val_accuracy: 0.8430\n"
     ]
    }
   ],
   "source": [
    "#모델 학습시키기\n",
    "hist = model.fit(x_train, y_train, epochs=50, \n",
    "                 batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS\n",
      "[0.5028541255182897, 0.4027849340332761, 0.37607589904405386, 0.3534483235656751, 0.3500036487855158, 0.3419539536597068, 0.3169018069367122, 0.3136036504097324, 0.29643609935834225, 0.2912946891482998, 0.2891414897253238, 0.28548137185570926, 0.2801390625743633, 0.28300520408488355, 0.2623263905166718, 0.2712515654898061, 0.263561957407001, 0.24536170037225039, 0.2662477498424464, 0.24990290912226654, 0.2479694716392025, 0.25208207562118273, 0.24213899883366002, 0.23285706527738337, 0.2433435702706802, 0.23150400475218677, 0.22003522081025054, 0.2299239002043864, 0.20933496134896432, 0.2192265058041978, 0.21851944766764647, 0.2013558997908344, 0.19843232247137255, 0.21055383989701382, 0.20355553248766664, 0.2041769082947024, 0.18904516594826312, 0.19787538466401175, 0.19734688267294107, 0.1999203417039952, 0.2012329216263318, 0.19819049495743699, 0.1876787948519902, 0.19108182892982367, 0.1741321456014646, 0.17961066280045154, 0.1691330900753499, 0.1761835165098061, 0.17166737249085848, 0.1801668659082559]\n",
      "223/223 [==============================] - 0s 27us/step\n",
      "LOSS_AND_METRICS\n",
      "[0.41853113345501136, 0.8430493474006653]\n",
      "XHAT\n",
      "[[0.0244431  0.03712399 0.02043126 0.07271814 0.13982773 0.03257627\n",
      "  0.03380737 0.03714946 0.5252525  0.4040404 ]]\n",
      "[[0. 1.]]\n",
      "YHAT\n",
      "[[0.01863284 0.9813672 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"LOSS\")\n",
    "print(hist.history['loss'])\n",
    "#print(hist.history['acc'])\n",
    "\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)\n",
    "print('LOSS_AND_METRICS')\n",
    "print(loss_and_metrics)\n",
    "\n",
    "xhat = x_test[0:1]\n",
    "print('XHAT')\n",
    "print(xhat)\n",
    "print(y_test[0:1])\n",
    "yhat = model.predict(xhat)\n",
    "print('YHAT')\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      delta   theta  lowAlpha  highAlpha  lowBeta  highBeta  lowGamma  \\\n",
      "0   1369077   56443     10774      12689     2862      4285      3340   \n",
      "1   2100580  294338    162799      93058    18074     27351      8665   \n",
      "2   1474510   78145     17494      41466     4960     33819     19584   \n",
      "3     44295   92503      2256      30773     1071     43253      2714   \n",
      "4    187155   48902       456      23527     4643     40720      1988   \n",
      "5    157993   15391      3580      21217     2658     46332      1903   \n",
      "6   1271682  340131     10840     121983     4780     60023     41773   \n",
      "7   1171508   81088     27063       9374    72545     47294     52510   \n",
      "8    551257   96296     20278      98515     4865     93568     57504   \n",
      "9    826363   47070     12165      41179    10109    215997      5524   \n",
      "10   456867   23593      5022       9086     6785     37946      4289   \n",
      "\n",
      "    midGamma  Meditation  Attention  \n",
      "0        823          30         51  \n",
      "1       4995          37         50  \n",
      "2       3217          35         66  \n",
      "3        922          20         87  \n",
      "4       1126          14         96  \n",
      "5        995           1        100  \n",
      "6       4617           1        100  \n",
      "7       3119           1        100  \n",
      "8       3669           8         91  \n",
      "9       1730           1         91  \n",
      "10       743           1         91  \n",
      "XHAT\n",
      "     delta  theta  lowAlpha  highAlpha  lowBeta  highBeta  lowGamma  midGamma  \\\n",
      "0  1369077  56443     10774      12689     2862      4285      3340       823   \n",
      "\n",
      "   Meditation  Attention  \n",
      "0          30         51  \n",
      "YHAT\n",
      "[[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "dat=pd.read_csv('emer_test.csv')\n",
    "dat.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "print(dat)\n",
    "X = dat[['delta','theta','lowAlpha','highAlpha','lowBeta','highBeta','lowGamma','midGamma','Meditation','Attention']].to_numpy()\n",
    "xhat = dat[0:1]\n",
    "print('XHAT')\n",
    "print(xhat)\n",
    "yhat = model.predict(xhat)\n",
    "print('YHAT')\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
